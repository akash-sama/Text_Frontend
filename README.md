# Toxicity Detection Model in JavaScript

## Overview
This project demonstrates the implementation of a complex neural network using TensorFlow.js, making it possible to build and train the model entirely in the browser. The project is developed using HTML, CSS, and JavaScript, leveraging TensorFlow.js to facilitate the frontend-based machine learning processes.

## Features
- **Model Building and Training**: Initiate the building and training of the model directly in your browser with just a click.
- **Toxicity Detection**: Check if the text is toxic using various metrics. The model evaluates the text and flags potentially harmful content.
- **Visibility of Results**: Only texts flagged as highly toxic are displayed. Texts without issues are flagged as non-toxic.

## Getting Started

### Installation
1. Clone the repository to your local machine:
2. Open the `index.html` file in your browser to start using the application.

### Usage
1. Open the application in your browser.
2. Click on the "Check for Abuse" button. This will load and build the model.
3. Once the model is ready, enter the text you want to analyze in the provided text area.
4. Submit the text. The model will assess the content and display the toxicity results below the text area.

## Development
This project was developed as a learning experience to understand the capabilities of TensorFlow.js in processing and training models in the frontend. The entire codebase is written in HTML, CSS, and JavaScript.

## License
This project is open-sourced under the MIT license. See the `LICENSE` file for more details.
